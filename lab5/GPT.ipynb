{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Загрузка датасета и его очистка"
      ],
      "metadata": {
        "id": "MNiKKuJn5V8m"
      },
      "id": "MNiKKuJn5V8m"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install kaggle\n",
        "!rm -r ~/.kaggle\n",
        "!mkdir ~/.kaggle\n",
        "!echo '{\"username\":\"midlow\",\"key\":\"19e4a7b3c26e4d040a5179c6b36318cd\"}' > ~/.kaggle/kaggle.json\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "!kaggle datasets download -d dhruvildave/wikibooks-dataset\n",
        "!unzip wikibooks-dataset.zip\n",
        "!rm wikibooks-dataset.zip\n",
        "!rm *.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "65u-9scqfy-4",
        "outputId": "dfe82ca8-b339-41fc-f5f7-ca476e32d8fa"
      },
      "id": "65u-9scqfy-4",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.5.13)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.16.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from kaggle) (2022.12.7)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.27.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.65.0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.1)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.26.15)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.4)\n",
            "rm: cannot remove '/root/.kaggle': No such file or directory\n",
            "Downloading wikibooks-dataset.zip to /content\n",
            "100% 1.82G/1.82G [01:20<00:00, 25.2MB/s]\n",
            "100% 1.82G/1.82G [01:20<00:00, 24.2MB/s]\n",
            "Archive:  wikibooks-dataset.zip\n",
            "  inflating: wikibooks.sqlite        \n",
            "rm: cannot remove '*.zip': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "590caa4b-00d7-4eb0-a2b3-b4b86ea663d4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "590caa4b-00d7-4eb0-a2b3-b4b86ea663d4",
        "outputId": "c092c7bf-80cd-4e0b-fa19-216df1ea1f4b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting keras-nlp\n",
            "  Downloading keras_nlp-0.5.2-py3-none-any.whl (527 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m527.7/527.7 kB\u001b[0m \u001b[31m34.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from keras-nlp) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras-nlp) (1.22.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras-nlp) (23.1)\n",
            "Collecting tensorflow-text (from keras-nlp)\n",
            "  Downloading tensorflow_text-2.12.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m108.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorflow-hub>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-text->keras-nlp) (0.13.0)\n",
            "Requirement already satisfied: tensorflow<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-text->keras-nlp) (2.12.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.13,>=2.12.0->tensorflow-text->keras-nlp) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.13,>=2.12.0->tensorflow-text->keras-nlp) (23.3.3)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.13,>=2.12.0->tensorflow-text->keras-nlp) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.13,>=2.12.0->tensorflow-text->keras-nlp) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.13,>=2.12.0->tensorflow-text->keras-nlp) (1.54.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.13,>=2.12.0->tensorflow-text->keras-nlp) (3.8.0)\n",
            "Requirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.13,>=2.12.0->tensorflow-text->keras-nlp) (0.4.8)\n",
            "Requirement already satisfied: keras<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.13,>=2.12.0->tensorflow-text->keras-nlp) (2.12.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.13,>=2.12.0->tensorflow-text->keras-nlp) (16.0.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.13,>=2.12.0->tensorflow-text->keras-nlp) (3.3.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.13,>=2.12.0->tensorflow-text->keras-nlp) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.13,>=2.12.0->tensorflow-text->keras-nlp) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.13,>=2.12.0->tensorflow-text->keras-nlp) (1.16.0)\n",
            "Requirement already satisfied: tensorboard<2.13,>=2.12 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.13,>=2.12.0->tensorflow-text->keras-nlp) (2.12.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.13,>=2.12.0->tensorflow-text->keras-nlp) (2.12.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.13,>=2.12.0->tensorflow-text->keras-nlp) (2.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.13,>=2.12.0->tensorflow-text->keras-nlp) (4.5.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.13,>=2.12.0->tensorflow-text->keras-nlp) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.13,>=2.12.0->tensorflow-text->keras-nlp) (0.32.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow<2.13,>=2.12.0->tensorflow-text->keras-nlp) (0.40.0)\n",
            "Requirement already satisfied: ml-dtypes>=0.0.3 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow<2.13,>=2.12.0->tensorflow-text->keras-nlp) (0.1.0)\n",
            "Requirement already satisfied: scipy>=1.7 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow<2.13,>=2.12.0->tensorflow-text->keras-nlp) (1.10.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow-text->keras-nlp) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow-text->keras-nlp) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow-text->keras-nlp) (3.4.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow-text->keras-nlp) (2.27.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow-text->keras-nlp) (0.7.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow-text->keras-nlp) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow-text->keras-nlp) (2.3.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow-text->keras-nlp) (5.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow-text->keras-nlp) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow-text->keras-nlp) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow-text->keras-nlp) (1.3.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow-text->keras-nlp) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow-text->keras-nlp) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow-text->keras-nlp) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow-text->keras-nlp) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow-text->keras-nlp) (2.1.2)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow-text->keras-nlp) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow-text->keras-nlp) (3.2.2)\n",
            "Installing collected packages: tensorflow-text, keras-nlp\n",
            "Successfully installed keras-nlp-0.5.2 tensorflow-text-2.12.1\n"
          ]
        }
      ],
      "source": [
        "!pip install keras-nlp"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import numpy as np\n",
        "import re\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from collections import Counter"
      ],
      "metadata": {
        "id": "73Yo-gyzfZRf"
      },
      "id": "73Yo-gyzfZRf",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sqlite3\n",
        "\n",
        "con = sqlite3.connect(\"wikibooks.sqlite\")\n",
        "df = pd.read_sql_query(\"SELECT body_text FROM en limit 10000\", con)\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "UawjacoKiH2_",
        "outputId": "2bf35d2c-38d6-4811-ce83-3492784cd5b5"
      },
      "id": "UawjacoKiH2_",
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                           body_text\n",
              "0  Front Page: Radiation Oncology | RTOG Trials |...\n",
              "1  Băuturi/Beverages[edit | edit source]\\nTea : C...\n",
              "2  Karrigell is an open Source Python web framewo...\n",
              "3  setupUnitPanel[edit | edit source]\\nHelper fun...\n",
              "4  Contents\\n\\n1 The Concept\\n2 The System\\n3 The..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a75f5cc8-1fb0-40b3-810a-3b2d18409a0d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>body_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Front Page: Radiation Oncology | RTOG Trials |...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Băuturi/Beverages[edit | edit source]\\nTea : C...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Karrigell is an open Source Python web framewo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>setupUnitPanel[edit | edit source]\\nHelper fun...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Contents\\n\\n1 The Concept\\n2 The System\\n3 The...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a75f5cc8-1fb0-40b3-810a-3b2d18409a0d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a75f5cc8-1fb0-40b3-810a-3b2d18409a0d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a75f5cc8-1fb0-40b3-810a-3b2d18409a0d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_text(s):\n",
        "    s = str(s)\n",
        "    s = re.sub(r'[^a-zA-Z0-9 ]', ' ', s)\n",
        "    s = re.sub('\\s\\W',' ',s)\n",
        "    s = re.sub('\\W,\\s',' ',s)\n",
        "    s = re.sub(\"\\d+\", \"\", s)\n",
        "    s = re.sub('\\s+',' ',s)\n",
        "    s = re.sub('[!@#$_]', '', s)\n",
        "    s = s.replace(\"co\",\"\")\n",
        "    s = s.replace(\"https\",\"\")\n",
        "    s = s.replace(\"[\\w*\",\" \")\n",
        "    return s"
      ],
      "metadata": {
        "id": "mN_nCX2-hKPm"
      },
      "id": "mN_nCX2-hKPm",
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bodies = df['body_text'].values\n",
        "bodies = list(map(preprocess_text, bodies))"
      ],
      "metadata": {
        "id": "uF4UX1KHhP08"
      },
      "id": "uF4UX1KHhP08",
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['body_text'] = pd.DataFrame(bodies)\n",
        "del bodies\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Y3AtiNE9hmVs",
        "outputId": "690ab1f1-d344-425b-a39f-47dfcb4db1ac"
      },
      "id": "Y3AtiNE9hmVs",
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                           body_text\n",
              "0  Front Page Radiation Onlogy RTOG Trials Random...\n",
              "1  B uturi Beverages edit edit source Tea Ceai Mi...\n",
              "2  Karrigell is an open Source Python web framewo...\n",
              "3  setupUnitPanel edit edit source Helper functio...\n",
              "4  Contents The Concept The System The Data LMI E..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d1ff601c-32bc-4f19-a9b9-297c11c1ccb0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>body_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Front Page Radiation Onlogy RTOG Trials Random...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>B uturi Beverages edit edit source Tea Ceai Mi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Karrigell is an open Source Python web framewo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>setupUnitPanel edit edit source Helper functio...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Contents The Concept The System The Data LMI E...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d1ff601c-32bc-4f19-a9b9-297c11c1ccb0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d1ff601c-32bc-4f19-a9b9-297c11c1ccb0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d1ff601c-32bc-4f19-a9b9-297c11c1ccb0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ds_train, ds_test = train_test_split(df['body_text'], test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "UIzIIKz6oB0T"
      },
      "id": "UIzIIKz6oB0T",
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Length of train dataset = {len(ds_train)}\")\n",
        "print(f\"Length of test dataset = {len(ds_test)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nCMazYrSp4vE",
        "outputId": "adfd4ce6-eff9-4970-8ca4-90b7415281d7"
      },
      "id": "nCMazYrSp4vE",
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of train dataset = 8000\n",
            "Length of test dataset = 2000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Создание и обучение модели"
      ],
      "metadata": {
        "id": "dV26WYsv5jW7"
      },
      "id": "dV26WYsv5jW7"
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "b69b1540-5d3d-4860-ae6e-4f508707bc0d",
      "metadata": {
        "id": "b69b1540-5d3d-4860-ae6e-4f508707bc0d"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import keras_nlp\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "id": "a768b184-cf94-455c-9ee0-7d4fb493fdcc",
      "metadata": {
        "id": "a768b184-cf94-455c-9ee0-7d4fb493fdcc"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 128\n",
        "SEQ_LEN = 128\n",
        "MIN_TRAINING_SEQ_LEN = 450\n",
        "EMBED_DIM = 256\n",
        "FEED_FORWARD_DIM = 256\n",
        "NUM_HEADS = 3\n",
        "NUM_LAYERS = 2\n",
        "VOCAB_SIZE = 5000\n",
        "EPOCHS = 50\n",
        "NUM_TOKENS_TO_GENERATE = 80"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "id": "6e874903-2830-4360-a22e-b6313d68d796",
      "metadata": {
        "id": "6e874903-2830-4360-a22e-b6313d68d796"
      },
      "outputs": [],
      "source": [
        "raw_train_ds = (\n",
        "    tf.data.Dataset.from_tensor_slices(ds_train.values)\n",
        "    .filter(lambda x: tf.strings.length(x) > MIN_TRAINING_SEQ_LEN)\n",
        "    .batch(BATCH_SIZE)\n",
        "    .shuffle(buffer_size=256)\n",
        ")\n",
        "\n",
        "raw_val_ds = (\n",
        "    tf.data.Dataset.from_tensor_slices(ds_test.values)\n",
        "    .filter(lambda x: tf.strings.length(x) > MIN_TRAINING_SEQ_LEN)\n",
        "    .batch(BATCH_SIZE)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "id": "f39843c6-1d8e-4b72-add6-60a65e29b26e",
      "metadata": {
        "id": "f39843c6-1d8e-4b72-add6-60a65e29b26e"
      },
      "outputs": [],
      "source": [
        "vocab = keras_nlp.tokenizers.compute_word_piece_vocabulary(\n",
        "    raw_train_ds,\n",
        "    vocabulary_size=VOCAB_SIZE,\n",
        "    lowercase=True,\n",
        "    reserved_tokens=[\"[PAD]\", \"[UNK]\", \"[BOS]\"],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "id": "f775d52c-8837-4311-b805-8ea8a63987fa",
      "metadata": {
        "id": "f775d52c-8837-4311-b805-8ea8a63987fa"
      },
      "outputs": [],
      "source": [
        "tokenizer = keras_nlp.tokenizers.WordPieceTokenizer(\n",
        "    vocabulary=vocab,\n",
        "    sequence_length=SEQ_LEN,\n",
        "    lowercase=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "id": "37727439-168d-4663-b7c4-a74823830c71",
      "metadata": {
        "id": "37727439-168d-4663-b7c4-a74823830c71"
      },
      "outputs": [],
      "source": [
        "start_packer = keras_nlp.layers.StartEndPacker(\n",
        "    sequence_length=SEQ_LEN,\n",
        "    start_value=tokenizer.token_to_id(\"[BOS]\"),\n",
        ")\n",
        "\n",
        "\n",
        "def preprocess(inputs):\n",
        "    outputs = tokenizer(inputs)\n",
        "    features = start_packer(outputs)\n",
        "    labels = outputs\n",
        "    return features, labels\n",
        "\n",
        "\n",
        "train_ds = raw_train_ds.map(preprocess, num_parallel_calls=tf.data.AUTOTUNE).prefetch(\n",
        "    tf.data.AUTOTUNE\n",
        ")\n",
        "val_ds = raw_val_ds.map(preprocess, num_parallel_calls=tf.data.AUTOTUNE).prefetch(\n",
        "    tf.data.AUTOTUNE\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "id": "85de2646-2ea3-41dd-8423-1d61132fa27c",
      "metadata": {
        "id": "85de2646-2ea3-41dd-8423-1d61132fa27c"
      },
      "outputs": [],
      "source": [
        "inputs = keras.layers.Input(shape=(None,), dtype=tf.int32)\n",
        "embedding_layer = keras_nlp.layers.TokenAndPositionEmbedding(\n",
        "    vocabulary_size=VOCAB_SIZE,\n",
        "    sequence_length=SEQ_LEN,\n",
        "    embedding_dim=EMBED_DIM,\n",
        "    mask_zero=True,\n",
        ")\n",
        "x = embedding_layer(inputs)\n",
        "for _ in range(NUM_LAYERS):\n",
        "    decoder_layer = keras_nlp.layers.TransformerDecoder(\n",
        "        num_heads=NUM_HEADS,\n",
        "        intermediate_dim=FEED_FORWARD_DIM,\n",
        "    )\n",
        "    x = decoder_layer(x)\n",
        "outputs = keras.layers.Dense(VOCAB_SIZE)(x)\n",
        "model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "perplexity = keras_nlp.metrics.Perplexity(from_logits=True, mask_token_id=0)\n",
        "model.compile(optimizer=\"adam\", loss=loss_fn, metrics=['acc'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "id": "62df9fb3-4e35-4fcb-b633-226fdd5ccf61",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "62df9fb3-4e35-4fcb-b633-226fdd5ccf61",
        "outputId": "6369b3a5-0aa4-49e1-92df-d11e29d01ed4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_6 (InputLayer)        [(None, None)]            0         \n",
            "                                                                 \n",
            " token_and_position_embeddin  (None, None, 256)        1312768   \n",
            " g_5 (TokenAndPositionEmbedd                                     \n",
            " ing)                                                            \n",
            "                                                                 \n",
            " transformer_decoder_13 (Tra  (None, None, 256)        394749    \n",
            " nsformerDecoder)                                                \n",
            "                                                                 \n",
            " transformer_decoder_14 (Tra  (None, None, 256)        394749    \n",
            " nsformerDecoder)                                                \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, None, 5000)        1285000   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,387,266\n",
            "Trainable params: 3,387,266\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "id": "1c6b1342-fec7-4d94-b76d-e5ef5c86d064",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1c6b1342-fec7-4d94-b76d-e5ef5c86d064",
        "outputId": "c2f08bda-8313-4b62-8e28-eeb2175af21d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "98/98 - 33s - loss: 7.2174 - acc: 0.0354 - val_loss: 7.1251 - val_acc: 0.0359 - 33s/epoch - 334ms/step\n",
            "Epoch 2/50\n",
            "98/98 - 9s - loss: 6.8440 - acc: 0.0632 - val_loss: 6.1579 - val_acc: 0.1211 - 9s/epoch - 89ms/step\n",
            "Epoch 3/50\n",
            "98/98 - 10s - loss: 5.7062 - acc: 0.1473 - val_loss: 5.5261 - val_acc: 0.1609 - 10s/epoch - 99ms/step\n",
            "Epoch 4/50\n",
            "98/98 - 10s - loss: 5.1686 - acc: 0.1755 - val_loss: 5.3077 - val_acc: 0.1760 - 10s/epoch - 100ms/step\n",
            "Epoch 5/50\n",
            "98/98 - 10s - loss: 4.8435 - acc: 0.1963 - val_loss: 5.1957 - val_acc: 0.1883 - 10s/epoch - 97ms/step\n",
            "Epoch 6/50\n",
            "98/98 - 9s - loss: 4.5838 - acc: 0.2182 - val_loss: 5.1313 - val_acc: 0.1990 - 9s/epoch - 95ms/step\n",
            "Epoch 7/50\n",
            "98/98 - 9s - loss: 4.3601 - acc: 0.2392 - val_loss: 5.1049 - val_acc: 0.2065 - 9s/epoch - 89ms/step\n",
            "Epoch 8/50\n",
            "98/98 - 10s - loss: 4.1577 - acc: 0.2595 - val_loss: 5.1010 - val_acc: 0.2119 - 10s/epoch - 102ms/step\n",
            "Epoch 9/50\n",
            "98/98 - 10s - loss: 3.9731 - acc: 0.2802 - val_loss: 5.1267 - val_acc: 0.2153 - 10s/epoch - 98ms/step\n",
            "Epoch 10/50\n",
            "98/98 - 11s - loss: 3.8027 - acc: 0.3000 - val_loss: 5.1674 - val_acc: 0.2172 - 11s/epoch - 113ms/step\n",
            "Epoch 11/50\n",
            "98/98 - 10s - loss: 3.6417 - acc: 0.3203 - val_loss: 5.2266 - val_acc: 0.2181 - 10s/epoch - 103ms/step\n",
            "Epoch 12/50\n",
            "98/98 - 10s - loss: 3.4877 - acc: 0.3403 - val_loss: 5.3002 - val_acc: 0.2181 - 10s/epoch - 102ms/step\n",
            "Epoch 13/50\n",
            "98/98 - 10s - loss: 3.3532 - acc: 0.3575 - val_loss: 5.3815 - val_acc: 0.2192 - 10s/epoch - 98ms/step\n",
            "Epoch 14/50\n",
            "98/98 - 10s - loss: 3.2119 - acc: 0.3777 - val_loss: 5.4703 - val_acc: 0.2176 - 10s/epoch - 107ms/step\n",
            "Epoch 15/50\n",
            "98/98 - 9s - loss: 3.0960 - acc: 0.3936 - val_loss: 5.5602 - val_acc: 0.2170 - 9s/epoch - 90ms/step\n",
            "Epoch 16/50\n",
            "98/98 - 10s - loss: 2.9731 - acc: 0.4116 - val_loss: 5.6732 - val_acc: 0.2153 - 10s/epoch - 100ms/step\n",
            "Epoch 17/50\n",
            "98/98 - 11s - loss: 2.8605 - acc: 0.4289 - val_loss: 5.7718 - val_acc: 0.2141 - 11s/epoch - 110ms/step\n",
            "Epoch 18/50\n",
            "98/98 - 11s - loss: 2.7597 - acc: 0.4438 - val_loss: 5.8710 - val_acc: 0.2133 - 11s/epoch - 110ms/step\n",
            "Epoch 19/50\n",
            "98/98 - 9s - loss: 2.6675 - acc: 0.4577 - val_loss: 5.9836 - val_acc: 0.2103 - 9s/epoch - 91ms/step\n",
            "Epoch 20/50\n",
            "98/98 - 10s - loss: 2.5706 - acc: 0.4728 - val_loss: 6.1056 - val_acc: 0.2097 - 10s/epoch - 98ms/step\n",
            "Epoch 21/50\n",
            "98/98 - 10s - loss: 2.4852 - acc: 0.4865 - val_loss: 6.2236 - val_acc: 0.2079 - 10s/epoch - 99ms/step\n",
            "Epoch 22/50\n",
            "98/98 - 10s - loss: 2.4114 - acc: 0.4984 - val_loss: 6.3452 - val_acc: 0.2061 - 10s/epoch - 100ms/step\n",
            "Epoch 23/50\n",
            "98/98 - 9s - loss: 2.3251 - acc: 0.5121 - val_loss: 6.4652 - val_acc: 0.2072 - 9s/epoch - 96ms/step\n",
            "Epoch 24/50\n",
            "98/98 - 9s - loss: 2.2597 - acc: 0.5231 - val_loss: 6.5828 - val_acc: 0.2042 - 9s/epoch - 91ms/step\n",
            "Epoch 25/50\n",
            "98/98 - 10s - loss: 2.1859 - acc: 0.5350 - val_loss: 6.7115 - val_acc: 0.2024 - 10s/epoch - 100ms/step\n",
            "Epoch 26/50\n",
            "98/98 - 10s - loss: 2.1305 - acc: 0.5437 - val_loss: 6.8197 - val_acc: 0.2010 - 10s/epoch - 98ms/step\n",
            "Epoch 27/50\n",
            "98/98 - 10s - loss: 2.0665 - acc: 0.5545 - val_loss: 6.9532 - val_acc: 0.2013 - 10s/epoch - 103ms/step\n",
            "Epoch 28/50\n",
            "98/98 - 10s - loss: 2.0087 - acc: 0.5644 - val_loss: 7.0771 - val_acc: 0.1986 - 10s/epoch - 97ms/step\n",
            "Epoch 29/50\n",
            "98/98 - 10s - loss: 1.9585 - acc: 0.5725 - val_loss: 7.2053 - val_acc: 0.1970 - 10s/epoch - 98ms/step\n",
            "Epoch 30/50\n",
            "98/98 - 10s - loss: 1.9006 - acc: 0.5829 - val_loss: 7.3250 - val_acc: 0.1963 - 10s/epoch - 99ms/step\n",
            "Epoch 31/50\n",
            "98/98 - 10s - loss: 1.8537 - acc: 0.5904 - val_loss: 7.4413 - val_acc: 0.1955 - 10s/epoch - 103ms/step\n",
            "Epoch 32/50\n",
            "98/98 - 10s - loss: 1.8081 - acc: 0.5985 - val_loss: 7.5569 - val_acc: 0.1935 - 10s/epoch - 99ms/step\n",
            "Epoch 33/50\n",
            "98/98 - 10s - loss: 1.7761 - acc: 0.6031 - val_loss: 7.6747 - val_acc: 0.1939 - 10s/epoch - 98ms/step\n",
            "Epoch 34/50\n",
            "98/98 - 10s - loss: 1.7319 - acc: 0.6109 - val_loss: 7.7846 - val_acc: 0.1930 - 10s/epoch - 99ms/step\n",
            "Epoch 35/50\n",
            "98/98 - 9s - loss: 1.6873 - acc: 0.6192 - val_loss: 7.9144 - val_acc: 0.1932 - 9s/epoch - 89ms/step\n",
            "Epoch 36/50\n",
            "98/98 - 10s - loss: 1.6505 - acc: 0.6261 - val_loss: 8.0361 - val_acc: 0.1915 - 10s/epoch - 99ms/step\n",
            "Epoch 37/50\n",
            "98/98 - 9s - loss: 1.6137 - acc: 0.6317 - val_loss: 8.1463 - val_acc: 0.1903 - 9s/epoch - 96ms/step\n",
            "Epoch 38/50\n",
            "98/98 - 11s - loss: 1.5838 - acc: 0.6373 - val_loss: 8.2643 - val_acc: 0.1903 - 11s/epoch - 108ms/step\n",
            "Epoch 39/50\n",
            "98/98 - 9s - loss: 1.5519 - acc: 0.6430 - val_loss: 8.3820 - val_acc: 0.1890 - 9s/epoch - 90ms/step\n",
            "Epoch 40/50\n",
            "98/98 - 10s - loss: 1.5187 - acc: 0.6491 - val_loss: 8.5002 - val_acc: 0.1886 - 10s/epoch - 101ms/step\n",
            "Epoch 41/50\n",
            "98/98 - 10s - loss: 1.4884 - acc: 0.6550 - val_loss: 8.6199 - val_acc: 0.1886 - 10s/epoch - 99ms/step\n",
            "Epoch 42/50\n",
            "98/98 - 10s - loss: 1.4721 - acc: 0.6569 - val_loss: 8.7158 - val_acc: 0.1874 - 10s/epoch - 99ms/step\n",
            "Epoch 43/50\n",
            "98/98 - 9s - loss: 1.4343 - acc: 0.6645 - val_loss: 8.8530 - val_acc: 0.1871 - 9s/epoch - 89ms/step\n",
            "Epoch 44/50\n",
            "98/98 - 10s - loss: 1.4055 - acc: 0.6701 - val_loss: 8.9561 - val_acc: 0.1854 - 10s/epoch - 100ms/step\n",
            "Epoch 45/50\n",
            "98/98 - 10s - loss: 1.3855 - acc: 0.6733 - val_loss: 9.0595 - val_acc: 0.1848 - 10s/epoch - 99ms/step\n",
            "Epoch 46/50\n",
            "98/98 - 10s - loss: 1.3611 - acc: 0.6774 - val_loss: 9.1783 - val_acc: 0.1841 - 10s/epoch - 99ms/step\n",
            "Epoch 47/50\n",
            "98/98 - 9s - loss: 1.3423 - acc: 0.6806 - val_loss: 9.2771 - val_acc: 0.1847 - 9s/epoch - 89ms/step\n",
            "Epoch 48/50\n",
            "98/98 - 10s - loss: 1.3120 - acc: 0.6870 - val_loss: 9.3891 - val_acc: 0.1866 - 10s/epoch - 99ms/step\n",
            "Epoch 49/50\n",
            "98/98 - 11s - loss: 1.2837 - acc: 0.6932 - val_loss: 9.5046 - val_acc: 0.1849 - 11s/epoch - 111ms/step\n",
            "Epoch 50/50\n",
            "98/98 - 10s - loss: 1.2681 - acc: 0.6956 - val_loss: 9.6118 - val_acc: 0.1845 - 10s/epoch - 99ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f4caacfe410>"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ],
      "source": [
        "model.fit(train_ds, validation_data=val_ds, epochs=EPOCHS, verbose=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Генерация текстов"
      ],
      "metadata": {
        "id": "bwuvxf7J5pdU"
      },
      "id": "bwuvxf7J5pdU"
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_tokens = start_packer(tokenizer([\"\"]))\n",
        "prompt_tokens"
      ],
      "metadata": {
        "id": "nStM8iVOYVa5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50773d47-833b-4d2f-ab98-98d839d52a68"
      },
      "id": "nStM8iVOYVa5",
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 128), dtype=int32, numpy=\n",
              "array([[2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
              "      dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def next(prompt, cache, index):\n",
        "    logits = model(prompt)[:, index - 1, :]\n",
        "    hidden_states = None\n",
        "    return logits, hidden_states, cache"
      ],
      "metadata": {
        "id": "7K9GCpyKYbss"
      },
      "id": "7K9GCpyKYbss",
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sampler = keras_nlp.samplers.GreedySampler()\n",
        "output_tokens = sampler(\n",
        "    next=next,\n",
        "    prompt=prompt_tokens,\n",
        "    index=1,\n",
        ")\n",
        "txt = tokenizer.detokenize(output_tokens)\n",
        "print(f\"Greedy search generated text: \\n{txt}\\n\")"
      ],
      "metadata": {
        "id": "okSpggtFYcRL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5c021dd-b890-40a1-fee2-861dafa27270"
      },
      "id": "okSpggtFYcRL",
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Greedy search generated text: \n",
            "[b'[BOS] contents introduction history case studies areas index for hallo study for nas contents nas of ass and honorary devices for ho ho hoint three processing administrations overview note ho study questions motoroliethia to prohibites verbs indexybrotecasts bookiethroontine star constructional convention on edit edit source county contents edit edit source wikimedia objective of additional steps of additional information age procomics is a list of c programming languages abstract derived from cystic fa hpheritance majority of hous language skills largely warrion']\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sampler = keras_nlp.samplers.BeamSampler(num_beams=5)\n",
        "output_tokens = sampler(\n",
        "    next=next,\n",
        "    prompt=prompt_tokens,\n",
        "    index=1,\n",
        ")\n",
        "txt = tokenizer.detokenize(output_tokens)\n",
        "print(f\"Beam search generated text: \\n{txt}\\n\")"
      ],
      "metadata": {
        "id": "eUBHSFHUZpws",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2683bc10-3494-4d13-d307-f3377f25546f"
      },
      "id": "eUBHSFHUZpws",
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Beam search generated text: \n",
            "[b'[BOS] this page was imported and needs to be de wikified books should use wikilinks rather sparsely and only to reference technical or esoteric terms that are critical to understanding the ntent most if not all wikilinks should simply be removed please remove dewikify after the page is dewikified xmcd infinity of mass spectrospy depr nmr ray crystal condent solid ray crystallog ray crystallog ray crystallograp high spectangle mass spectrometry catal spectrospy debit romeign quanthelm ray beam buozz']\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sampler = keras_nlp.samplers.RandomSampler()\n",
        "output_tokens = sampler(\n",
        "    next=next,\n",
        "    prompt=prompt_tokens,\n",
        "    index=1,\n",
        ")\n",
        "txt = tokenizer.detokenize(output_tokens)\n",
        "print(f\"Random search generated text: \\n{txt}\\n\")"
      ],
      "metadata": {
        "id": "hl-gPwgFZ1rj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24f97fdc-7a63-4221-90a8-6d6516664b7e"
      },
      "id": "hl-gPwgFZ1rj",
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random search generated text: \n",
            "[b'[BOS] a reader requests expansion of this book to include more material you can help by adding new material learn how or ask for assistance in the reading room contents from computer science nouns predas and jennedance g references introduction edit edit source dvd refers to the ext is a device that a good question device to refer to the role quint phenyology bus the federal system analyslogists in national networkingiorating the federal software regarding the njunction status of status when operating system the teacher the money of others before describing different military lectures and methodifies or fashion the real authorized julizing the']\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sampler = keras_nlp.samplers.TopKSampler(k=5)\n",
        "output_tokens = sampler(\n",
        "    next=next,\n",
        "    prompt=prompt_tokens,\n",
        "    index=1,\n",
        ")\n",
        "txt = tokenizer.detokenize(output_tokens)\n",
        "print(f\"Top-K search generated text: \\n{txt}\\n\")"
      ],
      "metadata": {
        "id": "6s8ituBQaAXq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cba67e7c-f496-4df0-abf6-494f991007cc"
      },
      "id": "6s8ituBQaAXq",
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top-K search generated text: \n",
            "[b'[BOS] contents introduction what is social resources how you can play advantages and the role of using glossary assignment changed the current sequencing methods further reading devices for a list of all of allrustrate demonialsis in reinformoinformatics management variables edit edit source eroearts management system information for example of interchial regnition zeroing is the system for a function is exec library sounds routines that the system is used to the system used to the system exception of interge of all polish allocprocessor notation programmethrogative relationship operation and family well defined of the']\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sampler = keras_nlp.samplers.TopPSampler(p=0.7)\n",
        "output_tokens = sampler(\n",
        "    next=next,\n",
        "    prompt=prompt_tokens,\n",
        "    index=1,\n",
        ")\n",
        "txt = tokenizer.detokenize(output_tokens)\n",
        "print(f\"Top-P search generated text: \\n{txt}\\n\")"
      ],
      "metadata": {
        "id": "mGvOMzOsaMnh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6826990d-95ee-405c-979c-1b0eb40a972c"
      },
      "id": "mGvOMzOsaMnh",
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top-P search generated text: \n",
            "[b'[BOS] there are several catalogues together using rners editors prepositions this the acrdian of video editors like the webpages as a tool other words for reading this featureless you will discussing and more often because you can use to find the other contents adeque to learns other word entries print text editors preverbs usages as backspace selection tool writes of text edit edit source text here edit edit source when there is a bd for each page is no easy to say here you can write a gb bar left or left or rick the title hello world of the send tool script if you ve never']\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class TopKTextGenerator(keras.callbacks.Callback):\n",
        "    def __init__(self, k):\n",
        "        self.sampler = keras_nlp.samplers.TopKSampler(k)\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        output_tokens = self.sampler(\n",
        "            next=next,\n",
        "            prompt=prompt_tokens,\n",
        "            index=1,\n",
        "        )\n",
        "        txt = tokenizer.detokenize(output_tokens)\n",
        "        print(f\"Top-K search generated text: \\n{txt}\\n\")\n",
        "\n",
        "\n",
        "text_generation_callback = TopKTextGenerator(k=10)\n",
        "model.fit(train_ds.take(1), verbose=2, epochs=2, callbacks=[text_generation_callback])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dk6w5ELaDiut",
        "outputId": "e9eebfd2-286f-4f15-a6fb-d67c6826a29d"
      },
      "id": "dk6w5ELaDiut",
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "Top-K search generated text: \n",
            "[b'[BOS] contents introduction structure of enzymes mechanism of enzymes references introduction edit edit source enzymes many separate creating shared proteins and genetic processes are earactivity in cellular repdig reduce cystecharing to megulate different nutrition behaviour edit edit source an in a function is useful techniques for the mechanisms of the potential can be clearly ntribreas are essential stages of essential partic section protein that allow us toyste to protein molecules are functional for us these reactions to references to include a functional for the functional for example of the functional organs density prosector nurse protein nutrition in']\n",
            "\n",
            "1/1 - 6s - loss: 0.9629 - acc: 0.7774 - 6s/epoch - 6s/step\n",
            "Epoch 2/2\n",
            "Top-K search generated text: \n",
            "[b'[BOS] this book is a list of the best things about the pages with peer target type of control structures on a system list of external links to relation permissionsuse and rule and or labels and labels to a little here please info to another here please be me that invous and here this page in this page first be able to labeled with a single page that a date of the mathematics introduction provides first edition background none if you find maps is refuver edit edit source browser is the in terms for in the middlepostyknomorlinrhandk are on a higher level and have enough that if']\n",
            "\n",
            "1/1 - 7s - loss: 1.0960 - acc: 0.7392 - 7s/epoch - 7s/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f4c78774cd0>"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}